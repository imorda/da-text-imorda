{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import ast\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import youtokentome as yttm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:47:22.965689700Z",
     "start_time": "2023-12-27T15:47:22.002597600Z"
    }
   },
   "id": "cccca605dd446d36",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-27T13:20:11.079591500Z",
     "start_time": "2023-12-27T13:20:11.003451900Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2ch_posts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Byte-pair encoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cdf998639b2c5d1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13344/13344 [00:00<00:00, 555543.57it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('data/token_train.txt', 'w', encoding='utf8') as f:\n",
    "    for text in tqdm(df['text']):\n",
    "        f.write(text + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T00:44:52.957429400Z",
     "start_time": "2023-12-27T00:44:52.912244500Z"
    }
   },
   "id": "74655895cc32867c",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<youtokentome.youtokentome.BPE at 0x2080f2ade50>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yttm.BPE.train(data='data/token_train.txt', vocab_size=5000, model='models/bpe.model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T00:44:53.316766300Z",
     "start_time": "2023-12-27T00:44:52.957429400Z"
    }
   },
   "id": "c7560bd6ea5a577a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bpe = yttm.BPE('models/bpe.model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T13:32:47.894482800Z",
     "start_time": "2023-12-27T13:32:47.862541400Z"
    }
   },
   "id": "cf86ca08f6ab26ec",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['▁привет'], ['▁как'], ['▁дела'], ['▁са', 'п', '▁двач', '▁му', 'р', '-', 'му', 'р', '-', 'му', 'р', '-', 'му', 'р'], ['▁омежка'], ['▁оп'], ['▁т', 'ня'], ['▁тян'], ['▁сы', 'че', 'вать'], ['▁бамп']]\n"
     ]
    }
   ],
   "source": [
    "print(bpe.encode(['привет', 'как', 'дела', 'сап двач мур-мур-мур-мур', 'омежка', 'оп', 'тня', 'тян', 'сычевать', 'бамп'], output_type=yttm.OutputType.SUBWORD))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T00:44:53.365575600Z",
     "start_time": "2023-12-27T00:44:53.348414800Z"
    }
   },
   "id": "5a217b9966ebbd53",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Токенизация"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88be34278bf4a0c2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2ch_labeled_llama.csv', index_col='id')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:27:12.689591200Z",
     "start_time": "2023-12-27T15:27:12.612597300Z"
    }
   },
   "id": "78d327020b1c0117",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['text'] = bpe.encode(df['text'].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T00:44:53.531978400Z",
     "start_time": "2023-12-27T00:44:53.442166200Z"
    }
   },
   "id": "5e053532f775134a",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    text  toxic\nid                                                             \n0      [1423, 967, 698, 371, 475, 556, 284, 2441, 371...      1\n1                            [2348, 436, 312, 1145, 905]      0\n2                        [270, 312, 954, 1384, 1419, 37]      1\n3      [1350, 811, 1065, 288, 2425, 2109, 585, 269, 2...      1\n4                                [3071, 410, 3988, 2709]      1\n...                                                  ...    ...\n13147  [1033, 33, 2202, 483, 284, 310, 377, 349, 2950...      1\n13148  [313, 1768, 29, 310, 377, 349, 1397, 3548, 270...      0\n13149  [483, 361, 355, 1049, 284, 2098, 2421, 2504, 6...      0\n13150                                   [1882, 395, 929]      1\n13151  [614, 1062, 275, 1398, 278, 2358, 550, 3501, 1...      1\n\n[13152 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>toxic</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[1423, 967, 698, 371, 475, 556, 284, 2441, 371...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[2348, 436, 312, 1145, 905]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[270, 312, 954, 1384, 1419, 37]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[1350, 811, 1065, 288, 2425, 2109, 585, 269, 2...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[3071, 410, 3988, 2709]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13147</th>\n      <td>[1033, 33, 2202, 483, 284, 310, 377, 349, 2950...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13148</th>\n      <td>[313, 1768, 29, 310, 377, 349, 1397, 3548, 270...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13149</th>\n      <td>[483, 361, 355, 1049, 284, 2098, 2421, 2504, 6...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13150</th>\n      <td>[1882, 395, 929]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13151</th>\n      <td>[614, 1062, 275, 1398, 278, 2358, 550, 3501, 1...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>13152 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T00:44:53.548503600Z",
     "start_time": "2023-12-27T00:44:53.534488900Z"
    }
   },
   "id": "5ee680ec0f119f32",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.to_csv('data/2ch_labeled_llama_bpe.csv', index_label='id')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T00:44:53.658787900Z",
     "start_time": "2023-12-27T00:44:53.550505Z"
    }
   },
   "id": "7e3c29f71b87055a",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Обучение модели"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cba2619311810bc4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2ch_labeled_llama_bpe.csv', index_col='id')\n",
    "df['text'] = df['text'].apply(lambda x: ast.literal_eval(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:48:12.430753100Z",
     "start_time": "2023-12-27T15:48:12.180434400Z"
    }
   },
   "id": "29c32f23d4c3629",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the datasets into features (text) and targets (toxic)\n",
    "train_texts, train_labels = train['text'].tolist(), train['toxic'].tolist()\n",
    "test_texts, test_labels = test['text'].tolist(), test['toxic'].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:48:13.159400600Z",
     "start_time": "2023-12-27T15:48:13.123837800Z"
    }
   },
   "id": "301df7e2a804e824",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Convert lists to PyTorch tensors\n",
    "train_texts = [torch.tensor(seq) for seq in train_texts]\n",
    "test_texts = [torch.tensor(seq) for seq in test_texts]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:48:13.466256800Z",
     "start_time": "2023-12-27T15:48:13.425450700Z"
    }
   },
   "id": "ab2c99787e31d102",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "train_texts = pad_sequence(train_texts, batch_first=True, padding_value=0).to(dtype=torch.int64)\n",
    "test_texts = pad_sequence(test_texts, batch_first=True, padding_value=0).to(dtype=torch.int64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:48:13.760534Z",
     "start_time": "2023-12-27T15:48:13.726997900Z"
    }
   },
   "id": "b128567627c1f0b",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the actual maximum length after padding\n",
    "maxlen = train_texts.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:48:14.060479700Z",
     "start_time": "2023-12-27T15:48:14.048968500Z"
    }
   },
   "id": "a3599cdd71b63d91",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Convert labels to PyTorch tensors\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_labels = torch.tensor(test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:48:14.643625600Z",
     "start_time": "2023-12-27T15:48:14.630605100Z"
    }
   },
   "id": "22823f56763e4268",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TextClassifier(nn.ModuleList):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, hidden_lin_dim, train_mode):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.train_mode = train_mode\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # LSTM layer \n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_lin_dim)\n",
    "        if self.train_mode:\n",
    "            self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm = nn.BatchNorm1d(hidden_lin_dim, momentum=0.9)\n",
    "        self.fc2 = nn.Linear(hidden_lin_dim, 2)\n",
    "        self.activation1 = nn.Sigmoid()\n",
    "        self.activation2 = nn.Softmax()\n",
    "        \n",
    "        torch.nn.init.xavier_uniform(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform(self.fc2.weight)\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc1(x[:, -1, :])\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.activation1(x)\n",
    "        if self.train_mode:\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation2(x)\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:48:15.638837900Z",
     "start_time": "2023-12-27T15:48:15.630620200Z"
    }
   },
   "id": "359cb4947d220446",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Тимофей\\AppData\\Local\\Temp\\ipykernel_2572\\2140579863.py:21: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight)\n",
      "C:\\Users\\Тимофей\\AppData\\Local\\Temp\\ipykernel_2572\\2140579863.py:22: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc2.weight)\n",
      "c:\\users\\тимофей\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000... Loss: 0.7367... Train Accuracy: 59.61... Test Accuracy: 57.07...\n",
      "Epoch 2/100000... Loss: 0.7007... Train Accuracy: 53.57... Test Accuracy: 57.58...\n",
      "Epoch 3/100000... Loss: 0.6979... Train Accuracy: 45.02... Test Accuracy: 50.90...\n",
      "Epoch 4/100000... Loss: 0.6958... Train Accuracy: 41.35... Test Accuracy: 44.99...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 54\u001B[0m\n\u001B[0;32m     52\u001B[0m         _, predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(outputs\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     53\u001B[0m         totalTrain \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 54\u001B[0m         correctTrain \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mpredicted\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(epoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m, epochs),\n\u001B[0;32m     57\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoss: \u001B[39m\u001B[38;5;132;01m{:.4f}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(loss\u001B[38;5;241m.\u001B[39mitem()),\n\u001B[0;32m     58\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain Accuracy: \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(correctTrain \u001B[38;5;241m/\u001B[39m totalTrain \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m),\n\u001B[0;32m     59\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTest Accuracy: \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(correct \u001B[38;5;241m/\u001B[39m total \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "hidden_lin_dim = 15\n",
    "embedding_dim = 30\n",
    "hidden_dim = 15\n",
    "batch_size = 450\n",
    "vocab_size = 5000\n",
    "\n",
    "train = torch.utils.data.TensorDataset(train_texts, train_labels)\n",
    "test = torch.utils.data.TensorDataset(test_texts,test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TextClassifier(vocab_size, embedding_dim, hidden_dim, hidden_lin_dim, True).to(device)\n",
    "\n",
    "# Balance the weights of the loss function since the dataset is imbalanced\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels.numpy())\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 100000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Testing\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Testing\n",
    "    correctTrain = 0\n",
    "    totalTrain = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            totalTrain += labels.size(0)\n",
    "            correctTrain += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Epoch {}/{}...'.format(epoch+1, epochs),\n",
    "          'Loss: {:.4f}...'.format(loss.item()),\n",
    "          'Train Accuracy: {:.2f}...'.format(correctTrain / totalTrain * 100),\n",
    "          'Test Accuracy: {:.2f}...'.format(correct / total * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:48:29.357419Z",
     "start_time": "2023-12-27T15:48:24.099571800Z"
    }
   },
   "id": "75dd671aa949795b",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Сохранение модели"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c510cb3bb3b6c153"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/model.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T13:44:16.775873600Z",
     "start_time": "2023-12-27T13:44:16.751854600Z"
    }
   },
   "id": "8231e071914bdfd2",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Тимофей\\AppData\\Local\\Temp\\ipykernel_40084\\2140579863.py:21: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc1.weight)\n",
      "C:\\Users\\Тимофей\\AppData\\Local\\Temp\\ipykernel_40084\\2140579863.py:22: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.fc2.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": "TextClassifier(\n  (0): Embedding(5000, 30, padding_idx=0)\n  (1): LSTM(30, 15, batch_first=True)\n  (2): Linear(in_features=15, out_features=15, bias=True)\n  (3): BatchNorm1d(15, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n  (4): Linear(in_features=15, out_features=2, bias=True)\n  (5): Sigmoid()\n  (6): Softmax(dim=None)\n)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TextClassifier(vocab_size, embedding_dim, hidden_dim, hidden_lin_dim, False).to(device)\n",
    "model.load_state_dict(torch.load('models/model.pt'))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T13:45:33.601929800Z",
     "start_time": "2023-12-27T13:45:33.523144Z"
    }
   },
   "id": "f61da284925f307e",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    text = bpe.encode([text])\n",
    "    text = torch.tensor(text)\n",
    "    text = pad_sequence(text, batch_first=True, padding_value=0).to(dtype=torch.int64).to(device)\n",
    "    output = model(text)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    return \"Токсичные отходы\" if predicted.item() == 1 else \"Нормальный пост\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T13:45:34.193933300Z",
     "start_time": "2023-12-27T13:45:34.167911600Z"
    }
   },
   "id": "1efbf4acf39645eb",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\тимофей\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Нормальный пост'"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Сап двачику, как найти тян?')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:40:50.939613500Z",
     "start_time": "2023-12-27T15:40:50.884255500Z"
    }
   },
   "id": "f20c91e0e87477dc",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\тимофей\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Токсичные отходы'"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('ОП, ты серьёзно? Очередной двачевский тред про тян')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:40:51.764160800Z",
     "start_time": "2023-12-27T15:40:51.739140600Z"
    }
   },
   "id": "e705f8ab95f6a9ed",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\тимофей\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Токсичные отходы'"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Перформанс от github copilot:\n",
    "predict('Ебал мать ОПа, сука, ебал её в рот, ебал её в жопу, ебал её в пизду, ебал её в уши, ебал её в нос, ебал её в глаза, ебал её в волосатую пизду, ебал её в волосатую жопу, ебал её в волосатый рот, ебал её в волосатые уши, ебал её в волосатый нос, ебал её в волосатые глаза, ебал её в волосатые волосы, ебал её в волосатые ногти, ебал её в волосатые ресницы, ебал её в волосатые брови, ебал её в вол�')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:40:54.154163300Z",
     "start_time": "2023-12-27T15:40:54.113736500Z"
    }
   },
   "id": "6d4998f95f8e1168",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\тимофей\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Нормальный пост'"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Почему коммунизм не случился?')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:40:55.148697200Z",
     "start_time": "2023-12-27T15:40:55.113653400Z"
    }
   },
   "id": "4a41e18e686c1f0b",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\тимофей\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Нормальный пост'"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Я все пропустил, что за тема с вечеринки евлеевой? Есть пак со всеми фотками?')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:40:56.703070300Z",
     "start_time": "2023-12-27T15:40:56.658019800Z"
    }
   },
   "id": "e1de25c67494d25",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\тимофей\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Нормальный пост'"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"это результаты полугода работы в зале, шизик. Генетика у него, лол Еще и оправдывается мол дальше не шел\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T15:40:57.317806600Z",
     "start_time": "2023-12-27T15:40:57.280194300Z"
    }
   },
   "id": "61f92181e9c46e71",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\тимофей\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Нормальный пост'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T14:04:54.095756900Z",
     "start_time": "2023-12-27T14:04:54.046880500Z"
    }
   },
   "id": "d330d24cd274b5a4",
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
